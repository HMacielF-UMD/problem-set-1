

    # 1. Read in the dataframe(s) from PART 3
    df = pd.read_csv('data/df_arrests_test_with_predictions.csv')
    
    # Split the data into training and test sets
    df_train, df_test = train_test_split(
        df, 
        test_size=0.3, 
        shuffle=True, 
        stratify=df['y'], 
        random_state=42
    )

    # Define features and target variable
    features = ['num_fel_arrests_last_year', 'current_charge_felony']
    X_train = df_train[features]
    y_train = df_train['y']
    X_test = df_test[features]

    # 2. Define parameter grid for hyperparameter tuning
    param_grid_dt = {'max_depth': [1, 3, 5]}

    # Initialize the decision tree model
    dt_model = DTC()

    # Initialize GridSearchCV with 5-fold cross-validation
    gs_cv_dt = GridSearchCV(dt_model, param_grid_dt, cv=KFold_strat(n_splits=5), scoring='accuracy')

    # Fit the model to the training data
    gs_cv_dt.fit(X_train, y_train)

    # Optimal value for max_depth
    optimal_max_depth = gs_cv_dt.best_params_['max_depth']
    
    print(f"Optimal max_depth: {optimal_max_depth}")
    
    # Predict for the test set
    df_test['pred_dt'] = gs_cv_dt.predict(X_test)

    # Save predictions to a CSV file for further use
    df_test.to_csv('data/df_arrests_test_with_predictions_dt.csv', index=False)

    return df_test

# Run the decision tree function if this script is executed directly
if __name__ == "__main__":
    df_result = run_decision_tree()
    print("Decision tree completed and predictions saved to 'data/df_arrests_test_with_predictions_dt.csv'.")